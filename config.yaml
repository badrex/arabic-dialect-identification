project: adi5-vc
pretrained_model:  utter-project/mHuBERT-147 #facebook/mms-1b  #facebook/w2v-bert-2.0 #facebook/mms-300m  "facebook/wav2vec2-xls-r-300m", facebook/wav2vec2-large-xlsr-53
natural_dataset: adi5-aljazeera-arabic-dialects # path to natural speech dataset
resynthesized_dataset: adi5-aljazeera-arabic-dialects-vc-all # path to resynthesized dataset using vc or augmentation
sample_data: false #true
target_speakers:  [1, 6] #null # or [1, 3, 4, 6], choose from 1-6 spaker ID 
sample_size: 14589 # 14589 means no sampling
learning_rate: 0.00005  # for w2v-bert-2.0 use smaller lr ~  0.000005, MMS 0.00005 is fine
batch_size: 4
gradient_accumulation_steps: 4
num_train_epochs: 3
apply_vc: true # whether or not to use voice conversion as data augmentation
add_natural_data: true
max_duration: 10 # shorter audio duration (=10 sec) is better for training, faster to train and higher accuracy
apply_dropout: false
freeze_feature_extractor: false
random_seed: 842

